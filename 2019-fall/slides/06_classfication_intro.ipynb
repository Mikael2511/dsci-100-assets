{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DSCI 100 - Introduction to Data Science\n",
    "\n",
    "\n",
    "### Lecture 6 - Classification using K-Nearest Neighbours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### First, a little housekeeping\n",
    "\n",
    "1. Quiz grading will be finished as soon as possible!\n",
    "\n",
    "2. Please fill out the mid-course survey (if you already have, thanks!)\n",
    "\n",
    "<img align=\"left\" src=\"https://media.giphy.com/media/3o7TKU8RvQuomFfUUU/giphy.gif\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reminder  \n",
    "\n",
    "Where are we? Where are we going?\n",
    "\n",
    "<center>\n",
    "    <img src = \"https://d33wubrfki0l68.cloudfront.net/571b056757d68e6df81a3e3853f54d3c76ad6efc/32d37/diagrams/data-science.png\" width=\"800\"/>\n",
    "    </center>\n",
    "\n",
    "*source: [R for Data Science](https://r4ds.had.co.nz/) by Grolemund & Wickham*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "Suppose we have past data of cancer tumour cell diagnosis labelled \"benign\" and \"malignant\".\n",
    "\n",
    "Do you think a new cell with Concavity = 4.2 and Perimeter = -1 would be cancerous?\n",
    "\n",
    "<center><img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-multiknn-1-1.png\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## What kind of data analysis question is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-nearest neighbours classification\n",
    "\n",
    "*Predict the label / class for a new observation using the K closest points from our dataset.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Compute the distance between the new observation and each observation in our *training set*<br><br>\n",
    "\n",
    "<center>\n",
    "$\\text{Distance} = \\sqrt{(p_{\\text{new}} - p_{\\text{train}})^2 + (c_{\\text{new}} - c_{\\text{train}})^2}$\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-knn-2-1.png\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-nearest neighbours classification\n",
    "\n",
    "*Predict the label / class for a new observation using the K closest points from our dataset.*\n",
    "\n",
    "2. Sort the data in ascending order according to the distances\n",
    "3. Choose the top K rows as \"neighbours\"\n",
    "```\n",
    "##         ID Perimeter Concavity Class dist_from_new\n",
    "##      <dbl>     <dbl>     <dbl> <fct>         <dbl>\n",
    "## 1   859471    -1.24       4.70 B             0.553\n",
    "## 2 84501001    -0.286      3.99 M             0.744\n",
    "## 3  8710441    -1.08       2.63 B             1.57 \n",
    "## 4  9013838    -0.461      2.72 M             1.57 \n",
    "## 5   925622     0.638      4.30 M             1.64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-nearest neighbours classification\n",
    "\n",
    "*Predict the label / class for a new observation using the K closest points from our dataset.*\n",
    "\n",
    "4. Classify the new observation based on majority vote.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-multiknn-3-1.png\" width=\"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## What would the predicted class be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We can go beyond 2 predictors\n",
    "\n",
    "For two observations $u, v$, each with $m$ variables (columns) labelled $1, \\dots, m$,\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "   $\\text{Distance} = \\sqrt{(u_1-v_1)^2 + (u_2-v_2)^2 + \\dots + (u_m - v_m)^2}$ \n",
    "</center>\n",
    "\n",
    "Aside from that, it's the same algorithm!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Standardized Data\n",
    "\n",
    "What if one variable is much larger than the other? e.g. Salary (10,000+) and Age (0-100)\n",
    "\n",
    "*Standardize:* shift and scale so that the average is 0 and the standard deviation is 1.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/06-scaling-2-1.png\" width=\"1200\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unbalanced Data\n",
    "\n",
    "What if one label is far more common than another?\n",
    "\n",
    "E.g. if this is a very rare kind of cancer, we may have far more benign observations\n",
    "\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-unbalanced-1.png\" width=\"600\"/>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Will K = 7-Nearest Neighbours ever predict malignance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unbalanced Data\n",
    "\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-upsample-1.png\" width=\"600\"/>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unbalanced Data\n",
    "\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-upsample-2-1.png\" width=\"600\"/> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Oversampling to Rebalance\n",
    "\n",
    "Replicate the data in the smaller class to increase its count / voting power\n",
    "\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-upsample-plot-1.png\" width=\"600\"/>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to the `caret` package in R\n",
    "\n",
    "Caret handles computing distances, standardization, balancing, and prediction for us!\n",
    "\n",
    "0. Load the libraries and data we need (new: `caret`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(caret)\n",
    "\n",
    "cancer <- read_csv('data/clean-wdbc.data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to the `caret` package in R\n",
    "\n",
    "1. Split your table of training data into \n",
    "    - $Y$ (make this a vector)\n",
    "    - $X$'s (make this a `data.frame`, not a `tibble`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_train <- cancer %>%\n",
    "  select(\"Perimeter\", \"Concavity\")\n",
    "\n",
    "cancer_labels <- cancer %>% \n",
    "  select(Class) %>% \n",
    "  unlist()\n",
    "\n",
    "head(cancer_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to the `caret` package in R\n",
    "\n",
    "2. \"Fit\" your model:\n",
    "  - choose $k$ and create a `data.frame` with one column (named `k`) and one value\n",
    "  - use `train` and feed it $X$, $Y$, the method (\"knn\"), and $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k <- data.frame(k = 5)\n",
    "model_knn <- train(x = data.frame(cancer_train), y = cancer_labels, method='knn', tuneGrid = k)\n",
    "\n",
    "model_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to the `caret` package in R\n",
    "\n",
    "3. Predict $\\hat{Y}$ using your model by using `predict` and passing it your model object and the new observation (as a `data.frame`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obs <- data.frame(Perimeter = -1, Concavity = 4.2)\n",
    "predict(object=model_knn, new_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-multiknn-3-1.png\" width = \"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Go forth and ... model?\n",
    "\n",
    "<img align=\"left\" src=\"https://media.giphy.com/media/SJOEsdVR1Zha8/giphy.gif\" width=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Class challenge\n",
    "\n",
    "Suppose we have a new observation in the iris dataset, with \n",
    "\n",
    "- petal length = 5\n",
    "- petal width = 0.6\n",
    "\n",
    "Using R and the caret package, how would you classify this observation based on $k=3$ nearest neighbours?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Y_train <- select(iris, Species) %>% unlist()\n",
    "X_train <- select(iris, Petal.Length, Petal.Width) %>% data.frame()\n",
    "k = data.frame(k = 3)\n",
    "model_knn <- train(x = X_train, y = Y_train, method='knn', tuneGrid = k)\n",
    "new_obs <- data.frame(Petal.Length = 5, Petal.Width =  0.5)\n",
    "predict(object=model_knn, new_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 6, repr.plot.height = 3)\n",
    "ggplot(iris, aes(x = Petal.Length, y = Petal.Width, color = Species)) +\n",
    "    geom_point()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
